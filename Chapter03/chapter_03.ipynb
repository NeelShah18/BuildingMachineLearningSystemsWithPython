{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is supporting material for the book\n",
    "# Building Machine Learning Systems with Python\n",
    "# by Willi Richert, Luis Pedro Coelho and Matthieu Brucher\n",
    "# published by PACKT Publishing\n",
    "#\n",
    "# It is made available under the MIT License\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the magic command `%matplotlib` to see the plots inline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston dataset\n",
    "\n",
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first regression attempt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(fit_intercept=True)\n",
    "\n",
    "# Index number five in the number of rooms\n",
    "x = boston.data[:, 5]\n",
    "y = boston.target\n",
    "\n",
    "# lr.fit takes a two-dimensional array as input. We use np.atleast_2d\n",
    "# to convert from one to two dimensional, then transpose to make sure that the\n",
    "# format matches:\n",
    "x = np.transpose(np.atleast_2d(x))\n",
    "lr.fit(x, y)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_xlabel(\"Average number of rooms (RM)\")\n",
    "ax.set_ylabel(\"House Price\")\n",
    "xmin = x.min()\n",
    "xmax = x.max()\n",
    "ax.plot([xmin, xmax],\n",
    "        [lr.predict(xmin), lr.predict(xmax)],\n",
    "        '-', lw=2, color=\"#f9a602\")\n",
    "ax.scatter(x, y, s=2)\n",
    "fig.savefig('Regression_Fig_01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y, lr.predict(x))\n",
    "print(\"Mean squared error (on training data): {:.3}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mse)\n",
    "print('RMSE (on training data): {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y, lr.predict(x))\n",
    "print(\"R2 (on training data): {:.2}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat, but using all the input variables now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = boston.data\n",
    "\n",
    "lr.fit(x,y)\n",
    "\n",
    "mse = mean_squared_error(y, lr.predict(x))\n",
    "print(\"Mean squared error (on training data): {:.3}\".format(mse))\n",
    "rmse = np.sqrt(mse)\n",
    "print('RMSE (on training data): {}'.format(rmse))\n",
    "r2 = r2_score(y, lr.predict(x))\n",
    "print(\"R2 (on training data): {:.2}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how well we do, we plot _prediction vs. gold reality_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.set_xlabel('Predicted price')\n",
    "ax.set_ylabel('Actual price')\n",
    "ax.plot([y.min(), y.max()], [y.min(), y.max()], ':', lw=2, color=\"#f9a602\")\n",
    "ax.scatter(lr.predict(x), y, s=2)\n",
    "fig.savefig(\"Regression_FIG_02.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use **cross-validation** for evaluating the regression quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "kf = KFold(n_splits=5)\n",
    "p = cross_val_predict(lr, x, y, cv=kf)\n",
    "rmse_cv = np.sqrt(mean_squared_error(p, y))\n",
    "print('RMSE on 5-fold CV: {:.2}'.format(rmse_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compare a few different regression models on _both training data and using cross-validation_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, ElasticNet, Lasso, Ridge                              \n",
    "\n",
    "for name, met in [\n",
    "        ('linear regression', LinearRegression()),\n",
    "        ('elastic-net(.5)', ElasticNet(alpha=0.5)),\n",
    "        ('lasso(.5)', Lasso(alpha=0.5)),\n",
    "        ('ridge(.5)', Ridge(alpha=0.5)),\n",
    "]:\n",
    "    # Fit on the whole data:\n",
    "    met.fit(x, y)\n",
    "\n",
    "    # Predict on the whole data:\n",
    "    p = met.predict(x)\n",
    "    r2_train = r2_score(y, p)\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "    p = np.zeros_like(y)\n",
    "    for train, test in kf.split(x):\n",
    "        met.fit(x[train], y[train])\n",
    "        p[test] = met.predict(x[test])\n",
    "\n",
    "        r2_cv = r2_score(y, p)\n",
    "    print('Method: {}'.format(name))\n",
    "    print('R2 on training: {:.2}'.format(r2_train))\n",
    "    print('R2 on 5-fold CV: {:.2}'.format(r2_cv))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "las = Lasso(normalize=True)                            \n",
    "alphas = np.logspace(-5, 2, 1000)                   \n",
    "alphas, coefs, _= las.path(x, y, alphas=alphas)     \n",
    "\n",
    "fig,ax = plt.subplots()                             \n",
    "ax.plot(alphas, coefs.T)                            \n",
    "ax.set_xscale('log')                                \n",
    "ax.set_xlim(alphas.max(), alphas.min())             \n",
    "\n",
    "\n",
    "ax.set_xlabel('Lasso coefficient path as a function of alpha')                                           \n",
    "ax.set_xlabel('Alpha')                              \n",
    "ax.set_ylabel('Coefficient weight')                 \n",
    "fig.savefig('REGRESSION_FIG_03.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and do the same with Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size, epochs\n",
    "batch_size = 100\n",
    "n_epochs = 50000\n",
    "steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the scaffolding\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = boston.data[:,5][:,None]\n",
    "y = np.reshape(boston.target, (-1, 1))\n",
    "\n",
    "nb_features = x.shape[1]\n",
    "\n",
    "X = tf.placeholder(shape=[None, nb_features], dtype=tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32, name=\"y\")\n",
    "\n",
    "A = tf.Variable(tf.random_normal(shape=[nb_features, 1]), name=\"A\")\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1]), name=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the graph\n",
    "model_output = tf.matmul(X, A) + b\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(Y - model_output))\n",
    "\n",
    "# Uncomment to get Ridge or Lasso\n",
    "\"\"\"\n",
    "beta = 0.005\n",
    "regularizer = tf.nn.l2_loss(A)\n",
    "loss = loss + beta * regularizer\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "beta = 0.5\n",
    "regularizer = tf.reduce_mean(tf.abs(A))\n",
    "loss = loss + beta * regularizer\n",
    "\"\"\"\n",
    "\n",
    "grad_speed = 1e-3\n",
    "my_opt = tf.train.GradientDescentOptimizer(grad_speed)\n",
    "train_step = my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optimization\n",
    "loss_vec = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epochs):\n",
    "        permut = np.random.permutation(len(x))\n",
    "        for j in range(0, len(x), batch_size):\n",
    "            batch = permut[j:j+batch_size]\n",
    "            Xs = x[batch]\n",
    "            Ys = y[batch]\n",
    "\n",
    "            sess.run(train_step, feed_dict={X: Xs, Y: Ys})\n",
    "            temp_loss = sess.run(loss, feed_dict={X: Xs, Y: Ys})\n",
    "        \n",
    "        if epoch % steps == steps - 1:\n",
    "            temp_loss = sess.run(loss, feed_dict={X: x, Y: y})\n",
    "            loss_vec.append(temp_loss)\n",
    "\n",
    "            (A_, b_) = sess.run([A, b])\n",
    "            print('Epoch #%i  A = %s b = %s' % (epoch, np.transpose(A_), b_))\n",
    "            print('Loss = %.8f' % temp_loss)\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "    [slope, y_intercept] = sess.run([A, b])\n",
    "    prediction = sess.run(model_output, feed_dict={X: x})\n",
    "    mse = mean_squared_error(y, prediction)\n",
    "    print(\"Mean squared error (on training data): {:.3}\".format(mse))\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('RMSE (on training data): {}'.format(rmse))\n",
    "    r2 = r2_score(y, prediction)\n",
    "    print(\"R2 (on training data): {:.2}\".format(r2))\n",
    "\n",
    "best_fit = []\n",
    "for i in x:\n",
    "    best_fit.append(slope[0]*i+y_intercept[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1D best fit\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_xlabel(\"Average number of rooms (RM)\")\n",
    "ax.set_ylabel(\"House Price\")\n",
    "\n",
    "ax.scatter(x, y, s=2, label='Data Points')\n",
    "ax.plot(x, np.array(best_fit), '-', lw=2, color=\"#f9a602\", label='Best fit line')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "fig.savefig('REGRESSION_FIG_06.png')\n",
    "\n",
    "# Plot loss over time\n",
    "plt.figure()\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_title('Loss per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "\n",
    "ax.plot(loss_vec, 'k-')\n",
    "\n",
    "fig.savefig('REGRESSION_FIG_07.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we move to use all the features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the scaffolding\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = boston.data\n",
    "y = np.reshape(boston.target, (-1, 1))\n",
    "\n",
    "nb_features = x.shape[1]\n",
    "\n",
    "X = tf.placeholder(shape=[None, nb_features], dtype=tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32, name=\"y\")\n",
    "\n",
    "A = tf.Variable(tf.random_normal(shape=[nb_features, 1]), name=\"A\")\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1]), name=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the graph\n",
    "model_output = tf.matmul(X, A) + b\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(Y - model_output))\n",
    "\n",
    "# Uncomment to get Ridge or Lasso\n",
    "\"\"\"\n",
    "beta = 0.005\n",
    "regularizer = tf.nn.l2_loss(A)\n",
    "loss = loss + beta * regularizer\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "beta = 0.5\n",
    "regularizer = tf.reduce_mean(tf.abs(A))\n",
    "loss = loss + beta * regularizer\n",
    "\"\"\"\n",
    "\n",
    "grad_speed = 5e-7\n",
    "my_opt = tf.train.GradientDescentOptimizer(grad_speed)\n",
    "train_step = my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optimization\n",
    "loss_vec = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epochs):\n",
    "        permut = np.random.permutation(len(x))\n",
    "        for j in range(0, len(x), batch_size):\n",
    "            batch = permut[j:j+batch_size]\n",
    "            Xs = x[batch]\n",
    "            Ys = y[batch]\n",
    "\n",
    "            sess.run(train_step, feed_dict={X: Xs, Y: Ys})\n",
    "            temp_loss = sess.run(loss, feed_dict={X: Xs, Y: Ys})\n",
    "        \n",
    "        if epoch % steps == steps - 1:\n",
    "            temp_loss = sess.run(loss, feed_dict={X: x, Y: y})\n",
    "            loss_vec.append(temp_loss)\n",
    "\n",
    "            (A_, b_) = sess.run([A, b])\n",
    "            print('Epoch #%i  A = %s b = %s' % (epoch, np.transpose(A_), b_))\n",
    "            print('Loss = %.8f' % temp_loss)\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "    [slope, y_intercept] = sess.run([A, b])\n",
    "    prediction = sess.run(model_output, feed_dict={X: x})\n",
    "    mse = mean_squared_error(y, prediction)\n",
    "    print(\"Mean squared error (on training data): {:.3}\".format(mse))\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('RMSE (on training data): {}'.format(rmse))\n",
    "    r2 = r2_score(y, prediction)\n",
    "    print(\"R2 (on training data): {:.2}\".format(r2))\n",
    "\n",
    "best_fit = []\n",
    "for i in x:\n",
    "    best_fit.append(slope[0]*i+y_intercept[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss over time\n",
    "plt.figure()\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_title('Loss per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "\n",
    "ax.plot(loss_vec, 'k-')\n",
    "\n",
    "fig.savefig('REGRESSION_FIG_08.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## E2006 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "data, target = load_svmlight_file('data/E2006.train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute error on training data to demonstrate that we can obtain near perfect scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(data, target)\n",
    "pred = lr.predict(data) \n",
    "\n",
    "print('RMSE on training, {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))\n",
    "print('R2 on training, {:.2}'.format(r2_score(target, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we do not do so well on cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "pred = cross_val_predict(lr, data, target, cv=kf)\n",
    "\n",
    "print('RMSE on testing (5 fold), {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))\n",
    "print('R2 on testing (5 fold), {:.2}'.format(r2_score(target, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try _an Elastic net_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the lines below if you want to switch method:                                                     \n",
    "met = ElasticNet(alpha=0.1)\n",
    "met.fit(data, target)\n",
    "pred = met.predict(data)\n",
    "\n",
    "print('[EN 0.1] RMSE on training: {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))\n",
    "print('[EN 0.1] R2 on training: {:.2}'.format(r2_score(target, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a perfect prediction on the training data anymore, but let us check the value on cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cross_val_predict(met, data, target, cv=kf)\n",
    "\n",
    "print('[EN 0.1] RMSE on testing (5 fold): {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))\n",
    "print('[EN 0.1] R2 on testing (5 fold): {:.2}'.format(r2_score(target, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use `ElasticNetCV` to set parameters automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "# Construct an ElasticNetCV object (use all available CPUs)\n",
    "met = ElasticNetCV(n_jobs=-1)\n",
    "\n",
    "met.fit(data, target)\n",
    "pred = met.predict(data)\n",
    "print('[EN CV] RMSE on training, {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))\n",
    "print('[EN CV] R2 on training, {:.2}'.format(r2_score(target, pred)))\n",
    "\n",
    "pred = cross_val_predict(met, data, target, cv=kf)\n",
    "print('[EN CV] RMSE on testing (5 fold), {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))\n",
    "print('[EN CV] R2 on testing (5 fold), {:.2}'.format(r2_score(target, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a a pretty good general-purpose regression object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Construct an ElasticNetCV object (use all available CPUs)\n",
    "met = ElasticNetCV(n_jobs=-1, l1_ratio=[.01, .05, .25, .5, .75, .95, .99])\n",
    "\n",
    "pred = cross_val_predict(met, data, target, cv=kf)\n",
    "\n",
    "print('[EN CV l1_ratio] RMSE on testing(5 fold), {:.2}'.format(np.sqrt(mean_squared_error(target, pred))))\n",
    "print('[EN CV l1_ratio] R2 on testing (5 fold), {:.2}'.format(r2_score(target, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the final result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(target, pred, c='k', s=1)\n",
    "ax.plot([-5,-1], [-5,-1], 'r-', lw=2)\n",
    "ax.set_xlabel('Actual value')\n",
    "ax.set_ylabel('Predicted value')\n",
    "fig.savefig('REGRESSION_FIG_05.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
